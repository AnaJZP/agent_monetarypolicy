# analyzer.py
# VERSI√ìN AS√çNCRONA para an√°lisis en paralelo con orden cronol√≥gico

import json
import re
import asyncio
from datetime import datetime
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.callbacks import get_openai_callback

def extract_date_from_filename(filename: str):
    """
    Extrae fecha del nombre del archivo de informe de Banxico para ordenamiento cronol√≥gico.
    Formatos esperados: 'abril-junio 2024.pdf', 'enero-marzo 2025.pdf', etc.
    """
    # Diccionario de meses en espa√±ol
    months_map = {
        'enero': 1, 'febrero': 2, 'marzo': 3, 'abril': 4,
        'mayo': 5, 'junio': 6, 'julio': 7, 'agosto': 8,
        'septiembre': 9, 'octubre': 10, 'noviembre': 11, 'diciembre': 12
    }
    
    # Extraer a√±o
    year_match = re.search(r'(\d{4})', filename)
    if not year_match:
        return datetime(1900, 1, 1)  # Fecha por defecto para archivos sin a√±o
    
    year = int(year_match.group(1))
    
    # Extraer trimestre basado en el patr√≥n de nombres
    if 'enero-marzo' in filename.lower():
        month = 3  # Q1
    elif 'abril-junio' in filename.lower():
        month = 6  # Q2
    elif 'julio-septiembre' in filename.lower():
        month = 9  # Q3
    elif 'octubre-diciembre' in filename.lower():
        month = 12 # Q4
    else:
        # Buscar cualquier mes individual
        for month_name, month_num in months_map.items():
            if month_name in filename.lower():
                month = month_num
                break
        else:
            month = 1  # Por defecto enero
    
    return datetime(year, month, 1)

async def analyze_theme_research_grade(theme_name: str, search_query: str, vector_store, llm, report_filename: str):
    """
    An√°lisis tem√°tico as√≠ncrono de grado investigativo.
    """
    print(f"--> Analizando {theme_name} para {report_filename}...")
    
    retriever = vector_store.as_retriever(
        search_type="similarity",
        search_kwargs={'k': 25, 'filter': {'source_document': report_filename}}
    )
    
    try:
        # ASYNC: Usamos ainvoke para la recuperaci√≥n de documentos
        context_docs = await retriever.ainvoke(search_query)
    except Exception as e:
        print(f"    ‚ö†Ô∏è  Error en recuperaci√≥n con filtro: {e}")
        context_docs = []
    
    # B√∫squeda de respaldo si es necesario
    if not context_docs:
        print(f"    ‚ö†Ô∏è  No se encontraron documentos con filtro para {report_filename}. Intentando b√∫squeda general...")
        try:
            retriever_general = vector_store.as_retriever(search_type="similarity", search_kwargs={'k': 40})
            all_docs = await retriever_general.ainvoke(search_query)
            context_docs = [doc for doc in all_docs if doc.metadata.get('source_document') == report_filename]
        except Exception as e:
            print(f"    ‚ùå Error en b√∫squeda general: {e}")
            return f"‚Ä¢ Error recuperando informaci√≥n sobre {theme_name} en este informe: {str(e)}", 0.0

    if not context_docs:
        return f"‚Ä¢ No se encontr√≥ informaci√≥n relevante sobre {theme_name} en este informe.", 0.0
    
    context_text = "\n\n".join([doc.page_content for doc in context_docs])
    
    # === PROMPTS ADAPTADOS PARA BANXICO - VERSI√ìN CONCISA ===
    theme_prompts = {
        "inflacion": """
        Analiza este texto de informe trimestral de Banxico sobre inflaci√≥n. S√© CONCISO y directo.
        Proporciona un an√°lisis en m√°ximo 200 palabras cubriendo:
        
        **Evaluaci√≥n Actual:**
        ‚Ä¢ Nivel actual de inflaci√≥n (general y subyacente) vs objetivo 3% +/- 1%
        ‚Ä¢ Factores clave que impulsan la din√°mica inflacionaria
        
        **Perspectivas:**
        ‚Ä¢ Pron√≥sticos y balance de riesgos
        ‚Ä¢ Implicaciones para pol√≠tica monetaria
        
        Texto: {context}
        
        AN√ÅLISIS DE INFLACI√ìN (M√ÅXIMO 200 PALABRAS):
        """,
        
        "tasas_de_interes": """
        Analiza este texto de informe trimestral de Banxico sobre pol√≠tica monetaria. S√© CONCISO.
        An√°lisis en m√°ximo 200 palabras cubriendo:
        
        **Decisi√≥n de Pol√≠tica:**
        ‚Ä¢ Decisi√≥n sobre Tasa Objetivo y justificaci√≥n
        ‚Ä¢ Factores econ√≥micos clave que motivaron la decisi√≥n
        
        **Perspectivas:**
        ‚Ä¢ Gu√≠a a futuro sobre trayectoria de tasas
        ‚Ä¢ Postura relativa M√©xico vs Estados Unidos
        
        Texto: {context}
        
        AN√ÅLISIS DE TASAS (M√ÅXIMO 200 PALABRAS):
        """,
        
        "actividad_economica_empleo": """
        Analiza este texto de informe trimestral de Banxico sobre econom√≠a real. S√© CONCISO.
        An√°lisis en m√°ximo 200 palabras cubriendo:
        
        **Condiciones Actuales:**
        ‚Ä¢ Crecimiento del PIB y componentes principales
        ‚Ä¢ Mercado laboral: desocupaci√≥n, empleo formal, salarios
        
        **Implicaciones:**
        ‚Ä¢ Condiciones de holgura econ√≥mica
        ‚Ä¢ Impacto en presiones inflacionarias futuras
        
        Texto: {context}
        
        AN√ÅLISIS ECON√ìMICO (M√ÅXIMO 200 PALABRAS):
        """
    }
    
    prompt_template = theme_prompts.get(theme_name, theme_prompts["inflacion"])
    prompt = ChatPromptTemplate.from_template(prompt_template)
    chain = prompt | llm | StrOutputParser()
    
    try:
        with get_openai_callback() as cb:
            # ASYNC: Usamos ainvoke para la llamada al LLM
            analysis = await chain.ainvoke({"context": context_text})
            cost = cb.total_cost
        
        print(f"    ‚úÖ {theme_name}: An√°lisis generado para {report_filename}.")
        return analysis.strip(), cost
        
    except Exception as e:
        print(f"    ‚ùå Error procesando {theme_name} en {report_filename}: {e}")
        return f"‚Ä¢ Error analizando {theme_name}: {str(e)}", 0.0

async def get_quantitative_scores(context_text: str, llm):
    """
    Extrae puntajes cuantitativos de forma as√≠ncrona.
    """
    scoring_prompt = ChatPromptTemplate.from_template(
        """
        Como analista cuantitativo de Banxico, extrae puntajes num√©ricos de este contexto de informe trimestral.
        Devuelve √öNICAMENTE un objeto JSON con estas claves exactas y valores float:
        {{
            "preocupacion_inflacion": 0.0, "preocupacion_crecimiento": 0.0,
            "fortaleza_empleo": 0.0, "incertidumbre_politica": 0.0,
            "senales_expansivas": 0.0, "senales_restrictivas": 0.0
        }}
        
        Gu√≠a de puntuaci√≥n (0.0 = bajo/d√©bil, 1.0 = alto/fuerte):
        - preocupacion_inflacion: Qu√© tan preocupado est√° Banxico por los riesgos inflacionarios.
        - preocupacion_crecimiento: Nivel de preocupaci√≥n sobre la actividad econ√≥mica/desaceleraci√≥n.
        - fortaleza_empleo: Qu√© tan fuerte es la situaci√≥n del mercado laboral y la econom√≠a en general.
        - incertidumbre_politica: Grado de incertidumbre en las se√±ales de pol√≠tica (riesgos, dudas, factores externos/internos).
        - senales_expansivas: Fuerza del lenguaje que sugiere una pol√≠tica monetaria m√°s laxa (Dovish).
        - senales_restrictivas: Fuerza del lenguaje que sugiere una pol√≠tica monetaria m√°s apretada (Hawkish).
        
        Contexto: {context}
        
        JSON:
        """
    )
    
    try:
        chain = scoring_prompt | llm | StrOutputParser()
        with get_openai_callback() as cb:
            # ASYNC: Usamos ainvoke
            scores_str = await chain.ainvoke({"context": context_text})
            cost = cb.total_cost
        
        # Extraer JSON del string de respuesta
        json_match = re.search(r'\{.*\}', scores_str, re.DOTALL)
        if json_match:
            scores = json.loads(json_match.group())
        else:
            scores = json.loads(scores_str.strip())
            
        return scores, cost
        
    except Exception as e:
        print(f"    Advertencia: No se pudieron extraer los puntajes cuantitativos: {e}")
        return {
            "preocupacion_inflacion": 0.0, "preocupacion_crecimiento": 0.0, 
            "fortaleza_empleo": 0.0, "incertidumbre_politica": 0.0,
            "senales_expansivas": 0.0, "senales_restrictivas": 0.0
        }, 0.0

async def get_report_analysis(report_filename: str, vector_store, llm):
    """
    An√°lisis completo as√≠ncrono para un √∫nico informe de Banxico.
    """
    print(f"-> Iniciando an√°lisis para: {report_filename}...")
    total_cost = 0.0
    
    # Recuperar todo el contenido del informe
    try:
        full_report_retriever = vector_store.as_retriever(
            search_type="similarity", 
            search_kwargs={'k': 100}
        )
        global_docs = await full_report_retriever.ainvoke(
            "pol√≠tica monetaria Banco de M√©xico decisi√≥n perspectiva Junta de Gobierno"
        )
        filtered_docs = [doc for doc in global_docs if doc.metadata.get('source_document') == report_filename]
    except Exception as e:
        print(f"!! Error recuperando documentos para {report_filename}: {e}")
        return None, 0.0
    
    if not filtered_docs:
        print(f"!! No se encontr√≥ contenido para {report_filename}")
        return None, 0.0
        
    context_text = "\n\n".join([doc.page_content for doc in filtered_docs])
    
    # Prompt mejorado para an√°lisis global - VERSION CONCISA
    global_analysis_prompt = ChatPromptTemplate.from_template(
        """
        Analiza este informe trimestral de Banxico. Devuelve SOLO el JSON, sin explicaciones adicionales:
        {{
            "monetary_stance": "Restrictiva" o "Expansiva" o "Neutral",
            "stance_score": float entre -2.0 y +2.0,
            "confidence_level": float entre 0.0 y 1.0,
            "forward_guidance": "Gu√≠a futura de Banxico en 1 frase (m√°x 100 caracteres)",
            "key_policy_signal": "Se√±al principal en 1 frase (m√°x 80 caracteres)"
        }}
        
        DEFINICIONES:
        **RESTRICTIVA**: AUMENTOS de tasas o mantenimiento alto + lenguaje anti-inflacionario
        **EXPANSIVA**: REDUCCIONES de tasas + lenguaje pro-crecimiento  
        **NEUTRAL**: MANTENIMIENTO sin sesgo claro + comunicaci√≥n dependiente de datos
        
        PUNTAJES:
        +2.0: Muy restrictiva | +1.0: Restrictiva | 0.0: Neutral | -1.0: Expansiva | -2.0: Muy expansiva
        
        Contexto: {context}
        
        JSON:
        """
    )
    
    stage_1_chain = global_analysis_prompt | llm | StrOutputParser()
    
    try:
        with get_openai_callback() as cb:
            global_analysis_str = await stage_1_chain.ainvoke({"context": context_text})
            total_cost += cb.total_cost
        
        # Extraer JSON del string de respuesta
        json_match = re.search(r'\{.*\}', global_analysis_str, re.DOTALL)
        if json_match:
            final_analysis = json.loads(json_match.group())
        else:
            final_analysis = json.loads(global_analysis_str.strip())
            
    except Exception as e:
        print(f"!! Error en an√°lisis global para {report_filename}: {e}")
        return None, total_cost

    # Obtener puntajes cuantitativos
    quant_scores, quant_cost = await get_quantitative_scores(context_text, llm)
    final_analysis.update(quant_scores)
    total_cost += quant_cost
    
    # Definir temas y sus queries de b√∫squeda
    themes = {
        "inflacion": "inflaci√≥n INPC subyacente no subyacente objetivo precios trayectoria pron√≥stico riesgos",
        "tasas_de_interes": "pol√≠tica monetaria tasa de inter√©s objetivo Junta de Gobierno postura decisi√≥n comunicado gu√≠a",
        "actividad_economica_empleo": "actividad econ√≥mica PIB holgura mercado laboral empleo desocupaci√≥n salarios crecimiento inversi√≥n consumo"
    }
    
    # ASYNC: Ejecutamos los an√°lisis tem√°ticos en paralelo para este informe
    theme_tasks = []
    for theme, query in themes.items():
        task = analyze_theme_research_grade(theme, query, vector_store, llm, report_filename)
        theme_tasks.append(task)
    
    # Esperar a que todos los an√°lisis tem√°ticos terminen
    theme_results = await asyncio.gather(*theme_tasks)
    
    # Agregar los resultados tem√°ticos al an√°lisis final
    for i, theme in enumerate(themes.keys()):
        summary_key = f"{theme}_summary"
        analysis, cost = theme_results[i]
        final_analysis[summary_key] = analysis
        total_cost += cost
    
    # Agregar metadata adicional
    final_analysis['processing_cost'] = total_cost
    final_analysis['report_filename'] = report_filename
    final_analysis['processing_timestamp'] = datetime.now().isoformat()
    
    print(f"‚úÖ An√°lisis completo para {report_filename}. Costo: ${total_cost:.4f}")
    return final_analysis, total_cost

async def analyze_all_reports(vector_store, llm, report_filenames=None):
    """
    Funci√≥n principal para analizar todos los informes de Banxico de forma as√≠ncrona,
    respetando el orden cronol√≥gico.
    
    Args:
        vector_store: Vector store con los documentos procesados
        llm: Modelo de lenguaje para el an√°lisis
        report_filenames: Lista opcional de nombres de archivos espec√≠ficos a analizar.
                         Si es None, obtendr√° todos los archivos √∫nicos del vector store.
    
    Returns:
        tuple: (lista de an√°lisis, costo total)
    """
    
    if report_filenames is None:
        # Obtener todos los nombres de archivos √∫nicos del vector store
        print("-> Obteniendo lista de informes del vector store...")
        try:
            # Hacer una b√∫squeda amplia para obtener todos los documentos
            retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={'k': 1000})
            all_docs = await retriever.ainvoke("Banxico pol√≠tica monetaria informe trimestral")
            
            # Extraer nombres √∫nicos de archivos
            unique_filenames = set()
            for doc in all_docs:
                source_doc = doc.metadata.get('source_document')
                if source_doc:
                    unique_filenames.add(source_doc)
            
            report_filenames = list(unique_filenames)
            print(f"-> Encontrados {len(report_filenames)} informes √∫nicos")
            
        except Exception as e:
            print(f"!! Error obteniendo lista de informes: {e}")
            return [], 0.0
    
    if not report_filenames:
        print("!! No se encontraron informes para analizar")
        return [], 0.0
    
    # ORDENAR CRONOL√ìGICAMENTE los informes
    print("-> Ordenando informes cronol√≥gicamente...")
    report_filenames_sorted = sorted(report_filenames, key=extract_date_from_filename)
    
    print("-> Orden cronol√≥gico de procesamiento:")
    for i, filename in enumerate(report_filenames_sorted, 1):
        date = extract_date_from_filename(filename)
        print(f"   {i:2d}. {filename} -> {date.strftime('%Y-%m')}")
    
    # Procesar los informes de forma SECUENCIAL para mantener el orden cronol√≥gico
    # (pero cada informe individual usa an√°lisis as√≠ncrono internamente)
    all_analyses = []
    total_cost = 0.0
    
    print(f"\n-> Iniciando an√°lisis secuencial de {len(report_filenames_sorted)} informes...")
    
    for i, filename in enumerate(report_filenames_sorted, 1):
        print(f"\n=== PROCESANDO INFORME {i}/{len(report_filenames_sorted)}: {filename} ===")
        
        try:
            analysis, cost = await get_report_analysis(filename, vector_store, llm)
            
            if analysis is not None:
                # Agregar informaci√≥n de orden cronol√≥gico
                analysis['chronological_order'] = i
                analysis['total_reports'] = len(report_filenames_sorted)
                
                all_analyses.append(analysis)
                total_cost += cost
                
                print(f"‚úÖ Completado {filename} (#{i}/{len(report_filenames_sorted)}) - Costo: ${cost:.4f}")
            else:
                print(f"‚ùå Fall√≥ el an√°lisis de {filename}")
                
        except Exception as e:
            print(f"‚ùå Error procesando {filename}: {e}")
            continue
    
    print(f"\nüéØ AN√ÅLISIS COMPLETO:")
    print(f"   ‚Ä¢ Informes procesados: {len(all_analyses)}/{len(report_filenames_sorted)}")
    print(f"   ‚Ä¢ Costo total: ${total_cost:.4f}")
    
    return all_analyses, total_cost

# Funci√≥n de conveniencia para an√°lisis de un solo informe
async def analyze_single_report(report_filename: str, vector_store, llm):
    """
    Conveniencia para analizar un solo informe espec√≠fico.
    
    Args:
        report_filename: Nombre del archivo a analizar
        vector_store: Vector store con los documentos
        llm: Modelo de lenguaje
    
    Returns:
        tuple: (an√°lisis, costo)
    """
    print(f"-> An√°lisis individual de: {report_filename}")
    return await get_report_analysis(report_filename, vector_store, llm)

# Funci√≥n para guardar resultados
def save_analysis_results(analyses: list, output_filename: str = "banxico_analysis_results.json"):
    """
    Guarda los resultados de an√°lisis en un archivo JSON.
    
    Args:
        analyses: Lista de an√°lisis generados
        output_filename: Nombre del archivo de salida
    """
    try:
        with open(output_filename, 'w', encoding='utf-8') as f:
            json.dump(analyses, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Resultados guardados en: {output_filename}")
        print(f"   ‚Ä¢ Total de an√°lisis: {len(analyses)}")
        
    except Exception as e:
        print(f"‚ùå Error guardando resultados: {e}")

# Ejemplo de uso
if __name__ == "__main__":
    # Este c√≥digo es solo para referencia, no se ejecutar√° autom√°ticamente
    print("M√≥dulo analyzer.py cargado correctamente.")
    print("Funciones disponibles:")
    print("  - analyze_all_reports(vector_store, llm)")
    print("  - analyze_single_report(filename, vector_store, llm)")
    print("  - save_analysis_results(analyses, filename)")